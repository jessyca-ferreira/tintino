## üê† Tintino ‚Äì Hist√≥rias Interativas com Intelig√™ncia Artificial

> **Objetivo**: Tornar a tecnologia uma aliada para hist√≥rias, estimulando a criatividade, a imagina√ß√£o e a autonomia das crian√ßas atrav√©s de um ambiente l√∫dico, educativo e interativo.

<p align="center">
  <img src="./assets/images/logo.png" alt="estuda-ai" width="60%">
</p>

**Tintino** √© um projeto desenvolvido para a disciplina de **Criatividade Computacional**, com o prop√≥sito de explorar o uso de **Intelig√™ncia Artificial** na cria√ß√£o de hist√≥rias **interativas e personalizadas para crian√ßas**.

A proposta do projeto √© transformar a experi√™ncia de contar hist√≥rias em algo mais **imaginativo, din√¢mico e multimodal**, por meio de:

üé® **Imagens Geradas por IA**: as cenas e personagens s√£o criados a partir de prompts, trazendo ilustra√ß√µes √∫nicas e encantadoras.

üéôÔ∏è **Narra√ß√£o por Voz**: com uso de s√≠ntese de voz, as hist√≥rias ganham vida por meio de √°udios expressivos e imersivos.

üó£Ô∏è **Intera√ß√µes por Fala e Escuta**: a crian√ßa pode participar das hist√≥rias, fazendo escolhas, respondendo perguntas e interagindo com os personagens por voz.

üñçÔ∏è **Avalia√ß√£o de Desenhos**: o sistema tamb√©m incentiva a criatividade ao permitir que a crian√ßa desenhe e receba um retorno gentil da IA, incentivando a express√£o art√≠stica.

## üöÄ Formas de Executar o Projeto

### üê≥ Usando Docker (Recomendado para Produ√ß√£o)

A forma mais simples de executar o projeto completo √© utilizando Docker Compose:

**Execu√ß√£o com logs vis√≠veis (modo tradicional):**
```bash
docker-compose up --build
```

**Execu√ß√£o em segundo plano (background):**
```bash
docker-compose up --build -d
```

**Para acompanhar os logs quando executando em background:**
```bash
docker-compose logs -f
```

**Para parar os containers:**
```bash
docker-compose down
```

**Acesso:**
- **Frontend (Interface)**: `http://localhost`
- **API**: `http://localhost/api`
- **Documenta√ß√£o da API**: `http://localhost/api/docs` ou `http://localhost/api/redoc`

> **‚ö†Ô∏è Nota**: O Docker √© excelente para deploy e execu√ß√£o completa, mas no Windows pode consumir mais recursos devido √† virtualiza√ß√£o. Para desenvolvimento, ou recursos limitados, considere a execu√ß√£o manual da API.

### üõ†Ô∏è Execu√ß√£o Manual (Recomendado para Desenvolvimento)

#### 1. Configurando o ambiente

Recomendamos criar um ambiente virtual para isolar as depend√™ncias do projeto, de prefer√™ncia com o conda:

**Usando Conda:**
```bash
conda create -n louie python=3.10.6
conda activate louie
```

**Usando venv:**
```bash
python3 -m venv .venv
# Linux/macOS
source .venv/bin/activate
# Windows
.venv\Scripts\activate
```

#### 2. Instala√ß√£o das depend√™ncias

As depend√™ncias do projeto est√£o **organizadas por componente** na pasta `requirements/` para facilitar a instala√ß√£o apenas do que voc√™ precisa:

**Para a API (Backend):**

A API √© o n√∫cleo do sistema que processa as requisi√ß√µes e se comunica com os modelos de IA. 

**Primeiro, instale as depend√™ncias principais:**
```bash
pip install -r requirements/api.txt
```

**Depois, se quiser usar modelos locais, instale uma das extens√µes:**
```bash
# Para usar Whisper local com GPU NVIDIA + CUDA (processamento local mais r√°pido)
pip install -r requirements/api_nvidia.txt

# Para usar Whisper local apenas com CPU (processamento local mais lento)
pip install -r requirements/api-cpu.txt
```

> **‚ö†Ô∏è Importante**: 
> - O `api.txt` cont√©m todas as depend√™ncias b√°sicas e permite usar Whisper via API da OpenAI (recomendado)
> - Os outros arquivos (`api_nvidia.txt` e `api-cpu.txt`) cont√™m apenas Whisper e PyTorch para execu√ß√£o local
> - Para usar Whisper via API: configure a chave `OPENAI_API_KEY` no arquivo `.env`
> - Para usar Whisper local: configure `use_api = false` no arquivo `config.toml`

**Para a Interface (Frontend):**

A interface √© a parte visual do projeto (Streamlit) que os usu√°rios v√£o interagir:

```bash
pip install -r requirements/st.txt
```

> **üí° Dica**: Se voc√™ for desenvolver ou usar ambos (API + Interface), instale as duas depend√™ncias. Se for apenas testar a API, instale apenas a primeira.

#### 3. Depend√™ncias do Sistema

**üì¶ FFmpeg (Obrigat√≥rio):**

- **Linux**: `sudo apt install ffmpeg`
- **macOS**: `brew install ffmpeg`
- **Windows/Conda**: `conda install ffmpeg`

**ü™Ñ Python Magic:**

- **Windows**: Use `python-magic-bin` em vez de `python-magic`:
  ```bash
  pip install python-magic-bin
  ```
  > O `python-magic-bin` j√° inclui as depend√™ncias bin√°rias necess√°rias para Windows.

- **Linux/macOS**: O `python-magic` padr√£o funciona corretamente.

#### 4. Configura√ß√£o de vari√°veis de ambiente

Crie um arquivo `.env` na raiz do projeto com suas chaves de API:

```env
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
```

> **üí° Dica**: Existe um arquivo `env.example` na raiz do projeto que voc√™ pode usar como modelo. Basta copi√°-lo para `.env` e preencher com suas chaves.

#### 5. Executando os servi√ßos

**API (Backend):**
```bash
uvicorn api.main:app --reload
```

**Interface (Frontend):**
```bash
streamlit run streamlit_app.py
```

**Acesso:**
- **API**: `http://localhost:8000`
- **Documenta√ß√£o da API**: `http://localhost:8000/docs`
- **Interface**: `http://localhost:8501`

---
